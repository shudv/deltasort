%==============================================================================
\section{Related Work}
\label{sec:related}
%==============================================================================

\textbf{Adaptive sorting algorithms} exploit existing order in the input to improve performance on nearly sorted data. TimSort~\cite{timsort}, DriftSort~\cite{driftsort}, and natural mergesort~\cite{knuth1998art} dynamically identify monotonic runs and merge them efficiently, while a substantial body of work formalizes measures of presortedness and analyzes sorting complexity as a function of these measures rather than input size alone~\cite{5009382}. These approaches, however, \emph{assume no explicit knowledge of which values have been updated}.

\textbf{Incremental view maintenance (IVM)} is a fundamental and deeply researched problem, where updates to input data are propagated to derived results using explicit delta representations~\cite{10.5555/310709.310737, 10.1145/42192.42193, 10.14778/2824032.2824076, 7184878}. These techniques focus on maintaining query results, indexes, aggregates, and materialized views, and operate at the higher level of relational or dataflow operators rather than array-based sorting primitives. They treat deltas as first-class citizens and demonstrate the practical value of update-aware computation. However, they do not specifically address the lower level problem of incrementally sorting arrays, which is a much more specialized problem.

\textbf{Partial sorting} is another important problem where sorted output is read incrementally to avoid sorting everything upfront~\cite{chambers1971partial, paredes2006optimal}. This is a different model which addresses efficient selection rather than maintaining a fully sorted array under updates at all times.

\textbf{Dynamic data structures} offer a different trade-off. Self-balancing trees such as AVL trees~\cite{avl1962}, red--black trees~\cite{4567957}, B-trees~\cite{10.1145/1734663.1734671}, and skip lists~\cite{10.1145/78973.78977} support efficient ordered updates with logarithmic cost, but they do not preserve the contiguous layout and its associated advantages. A related idea is ``library sort''~\cite{DBLP:journals/corr/cs-DS-0407003}, which accelerates repeated insertions by maintaining gaps and hence does not preserve strictly contiguous layout by design.

\textbf{In-place merging algorithms} focus on merging two sorted arrays without using any additional space~\cite{kronrod1969optimal, 10.1145/42392.42403}. While there is some conceptual overlap with DeltaSort in the nature of implementation, both the problem model and the goal differ. In-place merging assumes both input arrays are fully sorted and prioritizes \emph{minimizing space usage}, whereas DeltaSort deals with a sorted array where some values have been updated and can be arbitrarily interspersed within the array, and the aim is to \emph{minimize execution time}. Moreover, many in-place merging algorithms rely on intricate block rearrangements and incur large constant factors, limiting their practical use despite optimal asymptotic bounds~\cite{franceschini2003optimal}.

Overall, this work focuses on a more specialized (but fundamental) problem: \emph{maintaining sorted order in contiguous arrays after a batch of in-place updates, under the assumption that the indices of updated values are explicitly available}. This setting is not addressed by adaptive sorting algorithms, system-level incremental indexing techniques, selection-based partial sorting algorithms or in-place merging algorithms. DeltaSort operates as a low-level sorting primitive that complements higher-level incremental systems while preserving the cache locality of array-based layouts. To our knowledge, \emph{no prior work has considered this exact sorting model}, and DeltaSort is the first algorithm to exploit the updated index information to achieve a non-trivial time-space trade-off between BIS and ESM.