%==============================================================================
\section{Introduction}
\label{sec:introduction}
%==============================================================================

Sorting is among the most heavily optimized primitives in modern systems, backed by decades of deep research. Standard library implementations---TimSort~\cite{timsort}, Introsort~\cite{musser1997introspective}, and DriftSort~\cite{driftsort} deliver excellent performance for general inputs by exploiting existing order, cache locality, and adaptive strategies. However, these algorithms operate under a \emph{blind} model: they discover structure dynamically rather than being explicitly informed about which values have been updated since the previous sort. While this makes things simpler for the caller, it also misses opportunities for optimization when such information is available. Modern systems often maintain metadata about updated records as part of their execution pipeline, making it possible to expose this information to lower-level sorting primitives. In the absence of a primitive that can accept this as a first-class input, they must either perform a full re-sort or design a custom incremental sorting solution if full re-sorting is prohibitively expensive.

As an example, consider a task management application that displays a large list of tasks sorted by priority or due date. Updates typically affect only a small subset of tasks at a time—for example, when a user completes a set of related tasks. The application can easily track which indices were updated, but in most implementations it still triggers a full re-sort and does not leverage the knowledge of updated indices to optimize the sorting process.

As another example, consider the problem of maintaining secondary indexes in databases and storage engines. Secondary indexes maintain reference to records ordered by a chosen attribute to support range queries and ordered scans. When records are inserted, deleted, or updated, the system must keep the secondary indexes consistent. Typically, databases build custom incremental maintenance solutions that internally track updated indices. There is an extensive line of work that studies efficient maintenance of materialised views using delta representations~\cite{gupta1995maintenance, nikolic2014incremental, akidau2015dataflow}. This suggests that a sorting primitive that can leverage knowledge of update indices could be broadly applicable.

Once the indices of the updates are known, how do we exploit this extra information to restore order more efficiently than performing a full re-sort? While this question arises across a wide range of systems, in this paper we deliberately focus on a lower level and widely used abstraction: maintaining sorted order in in-memory arrays which have a contiguous memory layout. Arrays underpin many higher-level systems—including in-memory caches, materialised views, and index representations—and serve as the execution substrate for most sorting primitives. Additionally, arrays uniquely admit SIMD/vectorization benefits~\cite{hennessy2017computer} which is a critical performance lever in modern systems. By focusing on arrays, we can isolate the algorithmic consequences of exposing update indices to the sorting routine and study the resulting trade-offs in a clean and concrete setting.

Existing approaches for incrementally sorting arrays already exploit this information, but they force a choice between two extremes:
\begin{enumerate}
  \item \textbf{Binary-Insertion-Sort (BIS):} Remove all updated values from the array and insert them back one by one using binary search. This approach uses $O(1)$ extra space but incurs $O(k n)$ data movement for $k$ updates in an array of size $n$, making it suitable only for very small update batches.
  \item \textbf{Extract–Sort–Merge (ESM):} Extract all updated values into a separate array, sort them using an efficient $O(k \log k)$ algorithm, and then merge them back into the original array. This approach uses $O(k \log k + n)$ time, but $O(n)$ extra space, even for small $k$, making it suitable only for larger update batches.
\end{enumerate}

This raises the question: are there other \emph{intermediate} algorithms that provide more balanced trade-offs? In this paper, we present such an algorithm. Specifically, this paper makes the following contributions:

\begin{enumerate}
  \item \textbf{Update-aware sorting model:} We formulate a sorting model in which the sorting routine is explicitly informed of the updated indices since the previous sort. Under this model, BIS and ESM serve as the baseline algorithms because they assume knowledge of what has been updated. 

  \item \textbf{DeltaSort algorithm:} We present \emph{DeltaSort}, an update-aware sorting algorithm, which offers a different set of trade-offs (\figref{tab:incremental-sorting-algorithms}) compared to existing approaches. In our experimental evaluation, for random updates, \emph{DeltaSort} outperforms BIS in execution time at the cost of modest extra space, and provides a more space-efficient alternative to ESM for intermediate update batch sizes, while still achieving speedups over full re-sorting.
\end{enumerate}

Although we study DeltaSort as a standalone algorithm for clarity, for practical application, it is best viewed as a \emph{building block} in a hybrid strategy that combines multiple update-aware techniques.
\input{\figdir/incremental-sorting-algorithms}

