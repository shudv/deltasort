%==============================================================================
\section{Introduction}
\label{sec:introduction}
%==============================================================================

Sorting is among the most heavily optimized primitives in modern systems, backed by decades of deep research. Standard library implementations---TimSort~\cite{timsort}, Introsort~\cite{musser1997introspective}, and DriftSort~\cite{driftsort} deliver excellent performance for general inputs by exploiting existing order, cache locality, and adaptive strategies. However, these algorithms operate under a \emph{blind} model: they discover structure dynamically rather than being explicitly informed about which values have been updated since the previous sort. While this model is more general and makes things straightforward for the caller, it also misses opportunities for optimization when such information is available. Modern systems often maintain metadata about updated records as part of their execution pipeline~\cite{kleppmann2017cdc}, making it possible to expose this information to lower-level sorting primitives. In the absence of a primitive that can accept this as a first-class input, they must either perform a full re-sort or use standard insertion-based or merge-based incremental techniques.

As an example, consider a modern client application that needs to display a large dynamic sorted list of items (e.g. task management applications or interactive dashboards). Modern applications have tight latency budgets for main-thread execution, beyond which users perceive the interface as unresponsive \cite{webdev_inp,card1983psychology}. As a result, UI frameworks commonly encourage memoization to avoid repeated recomputation of expensive derived values such as sorted views \cite{react_usememo}. However, such memoization is typically coarse-grained: cached results are invalidated whenever dependencies change, without exploiting knowledge of which positions were updated \cite{acar2006self}. Consequently, repeated full re-sorting can occupy the main thread long enough to exceed responsiveness budgets, leading to janky user experiences \cite{webdev_inp,googleRAIL}. If a sorting primitive could be informed of which elements were updated, it could potentially restore sorted order more efficiently than a full re-sort, enabling more responsive user interfaces.

Once the indices of the updates are known, how do we exploit this extra information to restore order more efficiently than performing a full re-sort? While similar questions arise for a variety of ordered data structures (e.g. B-Trees, heaps and BSTs), in this paper we deliberately focus on \textbf{arrays}, which provide a contiguous memory layout. This choice is intentional: arrays remain the dominant representation for sorted data in performance-critical systems because they offer superior cache locality and enable SIMD/vectorized processing~\cite{hennessy2017computer}—benefits that pointer-based structures fundamentally cannot provide. As a result, many systems prefer to preserve array layouts even when updates are frequent, rather than switching to fully dynamic structures~\cite{drepper2007memory,abadi2008columnstores,boncz2005monetdb}. This also allows us to cleanly isolate the algorithmic consequences of exposing update indices to the sorting routine and study the resulting trade-offs in a concrete setting.

Existing approaches for incrementally sorting arrays force a choice between two extremes:
\begin{enumerate}
  \item Binary-Insertion-Sort (\textbf{BIS}): Collect all updated values from the array and insert them back one by one using binary search. This approach uses $O(1)$ extra space but incurs $O(k n)$ data movement for $k$ updates in an array of size $n$, making it suitable only for very small update batches. This is the \emph{space-efficient but time-inefficient}  option on the trade-off frontier.
  \item Extract–Sort–Merge (\textbf{ESM}): Extract all updated values into a separate array, sort them using an efficient $O(k \log k)$ algorithm, and then merge them back into the original array. This approach uses $O(k \log k + n)$ time, but $O(n)$ extra space, even for small $k$, making it suitable only for larger update batches. This is the \emph{time-efficient but space-inefficient} option on the trade-off frontier.
\end{enumerate}

This raises the question: are there other algorithms that offer \emph{intermediate} trade-offs? To our knowledge, no prior work exploits knowledge of updated indices to achieve a better time-space trade-off than the two extremes listed above. In this paper, we fill that gap. Specifically, this paper makes the following contributions:

\begin{enumerate}
  \item \textbf{Update-aware sorting model:} We formulate a sorting model in which the sorting routine is explicitly informed of the updated indices since the previous sort. Under this model, BIS and ESM serve as the baseline algorithms because they can naturally exploit knowledge of which indices have been updated. 

  \item \textbf{DeltaSort algorithm:} We present \emph{DeltaSort}, an update-aware sorting algorithm, which offers distinct trade-offs (\figref{tab:incremental-sorting-algorithms}) as compared to existing approaches. We prove its correctness using loop invariants and illustrate its operation with examples.
  
  \item \textbf{Theoretical analysis:} Under a random bounded-range update model, we show that DeltaSort achieves $O(k \log n + n \sqrt{k})$ amortized time complexity while needing only $O(k)$ auxiliary space.
  
  \item \textbf{Experimental validation:} We implement DeltaSort in Rust and benchmark it against BIS, ESM, and full re-sorting on synthetic datasets. Our results show that DeltaSort is consistently faster than BIS in our evaluation and provides a space-efficient alternative to ESM across a wide range of update sizes.
\end{enumerate}

Although we study DeltaSort as a standalone algorithm for clarity, for practical application, it is best viewed as a \emph{building block} in a hybrid strategy that combines multiple update-aware techniques.
\input{\figdir/incremental-sorting-algorithms}

