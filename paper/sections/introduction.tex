%==============================================================================
\section{Introduction}
\label{sec:introduction}
%==============================================================================

Sorting is among the most heavily optimized primitives in modern systems, backed by decades of deep research. Standard library implementations---TimSort~\cite{timsort}, Introsort~\cite{musser1997introspective}, and PDQSort~\cite{peters2021pdqsort} deliver excellent performance for general inputs by exploiting partial order, cache locality, and adaptive strategies. However, these algorithms operate under a \emph{blind} model: they discover structure dynamically rather than being explicitly informed about which values have been updated since the previous sort. While this makes things simpler for the caller, it also misses opportunities for optimization when such information is available. Modern systems often maintain metadata about updated records as part of their execution pipeline, making it possible to expose this information to lower-level sorting primitives. But in absence of a primitive that can accept this as a first-class input, they either resort to full re-sort or design a custom incremental sorting solution on top of full sorting algorithms when full re-sorting is prohibitively expensive.

As an example, consider a task management application that displays a large list of tasks sorted by priority or due date. Updates typically affect only a small subset of items at a time—for example, when a user completes a set of related tasks. The application can easily track which indices were updated, but in most implementations it still triggers a full resort and does not leverage the knowledge of updated indices to optimize the sorting process. As another example, consider the problem of maintaining secondary indexes in databases and storage engines. Secondary indexes maintain reference to records ordered by a chosen attribute to support range queries and ordered scans. When records are inserted, deleted, or updated, the system must repair the secondary indexes to keep then consistent. Typically databases build custom incremental repair solutions that internally track updated indices and there is a whole line of work that studies efficient maintenance of materialized views using delta representations~\cite{gupta1995maintenance, nikolic2014incremental, akidau2015dataflow}. This shows us that a sorting primitive that can leverage knowledge of update indices would be broadly applicable.

Once the indices of the updates are known, a natural question arises: how can we explot this extra information to restore order more efficiently than performing a full re-sort? While this question arises across a wide range of systems, in this paper we deliberately focus on a core and widely used abstraction: maintaining sorted order in in-memory arrays which have a contiguous memory layout. Arrays underpin many higher-level systems—including in-memory caches, materialized views, and index representations—and serve as the execution substrate for most sorting primitives. By restricting attention to arrays, we can isolate the algorithmic consequences of exposing update indices to the sorting routine and study the resulting trade-offs in a clean and concrete setting. Existing approaches already exploit this information to some extent, but they force a choice between competing extremes:
\begin{enumerate}
  \item \textbf{Binary-Insertion-Sort (BIS):} For each updated index, remove the value and re-insert it at the correct position using binary search to find the insertion point. This approach uses $O(1)$ extra space, but $O(k n)$ data movement for $k$ updates in an array of size $n$, making it suitable only for very small update batches.
  \item \textbf{Extract–Sort–Merge (ESM):} Extract all updated values into a separate array, sort them using an efficient $O(k \log k)$ algorithm, and then merge them back into the original array. This approach uses $O(k \log k + n)$ time but $O(n)$ extra space even for small $k$, making it suitable only for larger update batches.
\end{enumerate}

This naturally raises the question: are there other intermediate strategies between these two extremes? In this paper, we present such a strategy. Specifically, this paper makes following contributions:

\begin{enumerate}
  \item \textbf{Update-aware sorting model:} We formulate a sorting model in which the sorting routine is explicitly informed of the updated indices since the previous sort. Under this model, Binary-Insertion-Sort and Extract-Sort-Merge serve as the baseline algorithms because they assume knowledge of what has been updated. 

  \item \textbf{DeltaSort algorithm:} We present \emph{DeltaSort}, an update-aware sorting algorithm, which offers a different set of trade-offs (\figref{tab:incremental-sorting-algorithms}) compared to existing approaches. In our experimental evaluation, \emph{DeltaSort} outperforms Binary-Insertion-Sort in execution time for small update batches ($k \ll n$), and provides a more space-efficient alternative to Extract-Sort-Merge for larger update batches ($k = \Theta (n)$).

  \input{\figdir/incremental-sorting-algorithms}

\end{enumerate}
