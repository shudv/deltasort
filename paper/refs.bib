@inproceedings{7184878,
  author    = {Aydin, Ahmet Arif and Anderson, Kenneth M.},
  booktitle = {2015 IEEE First International Conference on Big Data Computing Service and Applications},
  title     = {Incremental Sorting for Large Dynamic Data Sets},
  year      = {2015},
  volume    = {},
  number    = {},
  pages     = {170-175},
  keywords  = {Sorting;Indexes;Twitter;Scalability;Data analysis;Browsers;incremental sorting;dynamic data sets;big data},
  doi       = {10.1109/BigDataService.2015.35}
}

@article{chambers1971partial,
  author  = {Chambers, John M.},
  title   = {Algorithm 410: Partial Sorting},
  journal = {Communications of the ACM},
  volume  = {14},
  number  = {5},
  pages   = {357--358},
  year    = {1971},
  doi     = {10.1145/362588.362591}
}

@inproceedings{paredes2006optimal,
  title        = {Optimal incremental sorting},
  author       = {Paredes, Rodrigo and Navarro, Gonzalo},
  booktitle    = {2006 Proceedings of the Eighth Workshop on Algorithm Engineering and Experiments (ALENEX)},
  pages        = {171--182},
  year         = {2006},
  organization = {SIAM}
}

@misc{timsort,
  title        = {Timsort},
  author       = {Peters, Tim},
  howpublished = {\url{https://en.wikipedia.org/wiki/Timsort}},
  year         = {2002},
  note         = {Adopted by Java SE 7, Android, and V8}
}

@article{10.5555/261387.261395,
  author     = {Musser, David R.},
  title      = {Introspective sorting and selection algorithms},
  year       = {1997},
  issue_date = {Aug. 1997},
  publisher  = {John Wiley \& Sons, Inc.},
  address    = {USA},
  volume     = {27},
  number     = {8},
  issn       = {0038-0644},
  journal    = {Softw. Pract. Exper.},
  month      = aug,
  pages      = {983–993},
  numpages   = {11},
  keywords   = {STL, generic algorithms, heapsort, hybrid algorithms, introspective algorithms, quicksort, sorting algorithms}
}

@misc{driftsort,
  author       = {Voultapher},
  title        = {driftsort: an efficient, generic and robust stable sort implementation},
  year         = {2023},
  howpublished = {\url{https://github.com/Voultapher/driftsort}},
  note         = {Accessed: 2026-01-10}
}

@book{kleppmann2017ddiamodernsystems,
  author    = {Martin Kleppmann},
  title     = {Designing Data-Intensive Applications},
  publisher = {O'Reilly Media},
  year      = {2017},
  isbn      = {978-1449373320},
  pages     = {504--517}
}

@book{kleppmann2017cdc,
  author    = {Martin Kleppmann},
  title     = {Designing Data-Intensive Applications},
  publisher = {O'Reilly Media},
  year      = {2017},
  isbn      = {978-1449373320},
  pages     = {454--457}
}

@book{knuth1998art,
  title     = {The Art of Computer Programming, Volume 3: Sorting and Searching},
  author    = {Knuth, Donald E.},
  edition   = {2nd},
  year      = {1998},
  publisher = {Addison-Wesley}
}

@article{5009382,
  author   = {Mannila, Heikki},
  journal  = {IEEE Transactions on Computers},
  title    = {Measures of Presortedness and Optimal Sorting Algorithms},
  year     = {1985},
  volume   = {C-34},
  number   = {4},
  pages    = {318-325},
  keywords = {Sorting;Distance measurement;Algorithm design and analysis;Data mining;Atmospheric measurements;Particle measurements;Probability density function;Local insertion sort;measures;optimality;presortedness;sorting},
  doi      = {10.1109/TC.1985.5009382}
}

@article{avl1962,
  title   = {An Algorithm for the Organization of Information},
  author  = {Adelson-Velsky, Georgy M. and Landis, Evgenii M.},
  journal = {Proceedings of the USSR Academy of Sciences},
  volume  = {146},
  pages   = {263--266},
  year    = {1962}
}

@inproceedings{4567957,
  author    = {Guibas, Leo J. and Sedgewick, Robert},
  booktitle = {19th Annual Symposium on Foundations of Computer Science (sfcs 1978)},
  title     = {A dichromatic framework for balanced trees},
  year      = {1978},
  volume    = {},
  number    = {},
  pages     = {8-21},
  keywords  = {Computer science;Petroleum;Particle measurements;Algorithm design and analysis;Performance analysis},
  doi       = {10.1109/SFCS.1978.3}
}

@inproceedings{10.1145/1734663.1734671,
  author    = {Bayer, R. and McCreight, E.},
  title     = {Organization and maintenance of large ordered indices},
  year      = {1970},
  isbn      = {9781450379410},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/1734663.1734671},
  doi       = {10.1145/1734663.1734671},
  abstract  = {Organization and maintenance of an index for a dynamic random access file is considered. It is assumed that the index must be kept on some pseudo random access backup store like a disc or a drum. The index organization described allows retrieval, insertion, and deletion of keys in time proportional to logk I where I is the size of the index and k is a device dependent natural number such that the performance of the scheme becomes near optimal. Storage utilization is at least 50\% but generally much higher. The pages of the index are organized in a special data-structure, so-called B-trees. The scheme is analyzed, performance bounds are obtained, and a near optimal k is computed. Experiments have been performed with indices up to 100,000 keys. An index of size 15,000 (100,000) can be maintained with an average of 9 (at least 4) transactions per second on an IBM 360/44 with a 2311 disc.},
  booktitle = {Proceedings of the 1970 ACM SIGFIDET (Now SIGMOD) Workshop on Data Description, Access and Control},
  pages     = {107–141},
  numpages  = {35},
  keywords  = {random access files, paging, key retrieval, key insertion, key deletion, information retrieval, dynamic index maintenance, data structures},
  location  = {Houston, Texas},
  series    = {SIGFIDET '70}
}

@article{10.1145/78973.78977,
  author     = {Pugh, William},
  title      = {Skip lists: a probabilistic alternative to balanced trees},
  year       = {1990},
  issue_date = {June 1990},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {33},
  number     = {6},
  issn       = {0001-0782},
  url        = {https://doi.org/10.1145/78973.78977},
  doi        = {10.1145/78973.78977},
  abstract   = {Skip lists are data structures that use probabilistic balancing rather than strictly enforced balancing. As a result, the algorithms for insertion and deletion in skip lists are much simpler and significantly faster than equivalent algorithms for balanced trees.},
  journal    = {Commun. ACM},
  month      = {jun},
  pages      = {668–676},
  numpages   = {9},
  keywords   = {trees, searching, data structures}
}

@article{DBLP:journals/corr/cs-DS-0407003,
  author  = {Michael A. Bender and Martin Farach{-}Colton and Miguel A. Mosteiro},
  title   = {Insertion Sort is O(n log n)},
  journal = {CoRR},
  volume  = {cs.DS/0407003},
  year    = {2004}
}

@misc{deltasort-repo,
  title        = {{DeltaSort}: Reference implementation and benchmarks},
  author       = {Anonymous},
  year         = {2026},
  howpublished = {\url{https://www.dropbox.com/scl/fo/bi7mkpe94llo1bon2o7t3/AN0SegS5b-TCABRJErJTA9g?rlkey=ealdnsqsjkwfb4h1cbb4kyzvj&st=qjrh9owg&dl=0}},
  note         = {Rust and JavaScript implementations with unit tests and benchmark suite (anonymized for review)}
}

@inbook{10.5555/310709.310737,
  author    = {Gupta, Ashish and Mumick, Inderpal Singh},
  title     = {Maintenance of materialized views: problems, techniques, and applications},
  year      = {1999},
  isbn      = {0262571226},
  publisher = {MIT Press},
  address   = {Cambridge, MA, USA},
  booktitle = {Materialized Views: Techniques, Implementations, and Applications},
  pages     = {145–157},
  numpages  = {13}
}

@article{10.1145/42192.42193,
  author     = {Ryder, Barbara G. and Paull, Marvin C.},
  title      = {Incremental data-flow analysis algorithms},
  year       = {1988},
  issue_date = {Jan. 1988},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {10},
  number     = {1},
  issn       = {0164-0925},
  url        = {https://doi.org/10.1145/42192.42193},
  doi        = {10.1145/42192.42193},
  abstract   = {An incremental update algorithm modifies the solution of a problem that has been changed, rather than re-solving the entire problem. ACINCF and ACINCB are incremental update algorithms for forward and backward data-flow analysis, respectively, based on our equations model of Allen-Cocke interval analysis. In addition, we have studied their performance on a “nontoy” structured programming language L. Given a set of localized program changes in a program written in L, we identify a priori the nodes in its flow graph whose corresponding data-flow equations may be affected by the changes. We characterize these possibly affected nodes by their corresponding program structures and their relation to the original change sites, and do so without actually performing the incremental updates. Our results can be refined to characterize the reduced equations possibly affected if structured loop exit mechanisms are used, either singly or together, thereby relating richness of programming language usage to the ease of incremental updating.},
  journal    = {ACM Trans. Program. Lang. Syst.},
  month      = jan,
  pages      = {1–50},
  numpages   = {50}
}

@article{10.14778/2824032.2824076,
  author     = {Akidau, Tyler and Bradshaw, Robert and Chambers, Craig and Chernyak, Slava and Fern\'{a}ndez-Moctezuma, Rafael J. and Lax, Reuven and McVeety, Sam and Mills, Daniel and Perry, Frances and Schmidt, Eric and Whittle, Sam},
  title      = {The dataflow model: a practical approach to balancing correctness, latency, and cost in massive-scale, unbounded, out-of-order data processing},
  year       = {2015},
  issue_date = {August 2015},
  publisher  = {VLDB Endowment},
  volume     = {8},
  number     = {12},
  issn       = {2150-8097},
  url        = {https://doi.org/10.14778/2824032.2824076},
  doi        = {10.14778/2824032.2824076},
  abstract   = {Unbounded, unordered, global-scale datasets are increasingly common in day-to-day business (e.g. Web logs, mobile usage statistics, and sensor networks). At the same time, consumers of these datasets have evolved sophisticated requirements, such as event-time ordering and windowing by features of the data themselves, in addition to an insatiable hunger for faster answers. Meanwhile, practicality dictates that one can never fully optimize along all dimensions of correctness, latency, and cost for these types of input. As a result, data processing practitioners are left with the quandary of how to reconcile the tensions between these seemingly competing propositions, often resulting in disparate implementations and systems.We propose that a fundamental shift of approach is necessary to deal with these evolved requirements in modern data processing. We as a field must stop trying to groom unbounded datasets into finite pools of information that eventually become complete, and instead live and breathe under the assumption that we will never know if or when we have seen all of our data, only that new data will arrive, old data may be retracted, and the only way to make this problem tractable is via principled abstractions that allow the practitioner the choice of appropriate tradeoffs along the axes of interest: correctness, latency, and cost.In this paper, we present one such approach, the Dataflow Model, along with a detailed examination of the semantics it enables, an overview of the core principles that guided its design, and a validation of the model itself via the real-world experiences that led to its development.},
  journal    = {Proc. VLDB Endow.},
  month      = aug,
  pages      = {1792–1803},
  numpages   = {12}
}

@misc{v8elementskinds,
  title        = {Elements Kinds in {V8}},
  author       = {{Google V8 Team}},
  howpublished = {\url{https://v8.dev/blog/elements-kinds}},
  year         = {2017}
}

@book{hennessy2017computer,
  title     = {Computer Architecture: A Quantitative Approach},
  author    = {Hennessy, John L. and Patterson, David A.},
  edition   = {6},
  year      = {2017},
  publisher = {Morgan Kaufmann}
}

@book{feller1968,
  author    = {Feller, William},
  title     = {An Introduction to Probability Theory and Its Applications},
  volume    = {1},
  edition   = {3rd},
  publisher = {Wiley},
  year      = {1968}
}

@misc{react_usememo,
  author       = {{React Team}},
  title        = {useMemo},
  howpublished = {\url{https://react.dev/reference/react/useMemo}},
  year         = {2024},
  note         = {Accessed: 2026-01-10}
}

@misc{webdev_inp,
  author       = {{Google Chrome Team}},
  title        = {Interaction to Next Paint (INP)},
  howpublished = {\url{https://web.dev/articles/inp}},
  year         = {2023},
  note         = {Accessed: 2026-01-10}
}

@book{card1983psychology,
  title     = {The Psychology of Human-Computer Interaction},
  author    = {Card, Stuart K. and Moran, Thomas P. and Newell, Allen},
  year      = {1983},
  publisher = {Lawrence Erlbaum Associates}
}

@article{acar2006self,
  title   = {Self-adjusting Computation},
  author  = {Acar, Umut A. and Blelloch, Guy E. and Harper, Robert},
  journal = {ACM Transactions on Programming Languages and Systems},
  volume  = {28},
  number  = {3},
  pages   = {349--392},
  year    = {2006}
}

@misc{googleRAIL,
  title        = {The RAIL Performance Model},
  author       = {Google},
  howpublished = {\url{https://web.dev/rail/}},
  year         = {2015}
}

@misc{drepper2007memory,
  title        = {What Every Programmer Should Know About Memory},
  author       = {Ulrich Drepper},
  year         = {2007},
  howpublished = {\url{https://people.freebsd.org/~lstewart/articles/cpumemory.pdf}}
}

@article{boncz2005monetdb,
  author  = {Boncz, Peter and Zukowski, M. and Nes, Niels},
  year    = {2005},
  month   = {01},
  pages   = {},
  title   = {MonetDB/X100: Hyper-Pipelining Query Execution},
  journal = {2nd Biennial Conference on Innovative Data Systems Research, CIDR 2005}
}

@inproceedings{10.1145/1376616.1376712,
  author    = {Abadi, Daniel J. and Madden, Samuel R. and Hachem, Nabil},
  title     = {Column-stores vs. row-stores: how different are they really?},
  year      = {2008},
  isbn      = {9781605581026},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/1376616.1376712},
  doi       = {10.1145/1376616.1376712},
  abstract  = {There has been a significant amount of excitement and recent work on column-oriented database systems ("column-stores"). These database systems have been shown to perform more than an order of magnitude better than traditional row-oriented database systems ("row-stores") on analytical workloads such as those found in data warehouses, decision support, and business intelligence applications. The elevator pitch behind this performance difference is straightforward: column-stores are more I/O efficient for read-only queries since they only have to read from disk (or from memory) those attributes accessed by a query.This simplistic view leads to the assumption that one can obtain the performance benefits of a column-store using a row-store: either by vertically partitioning the schema, or by indexing every column so that columns can be accessed independently. In this paper, we demonstrate that this assumption is false. We compare the performance of a commercial row-store under a variety of different configurations with a column-store and show that the row-store performance is significantly slower on a recently proposed data warehouse benchmark. We then analyze the performance difference and show that there are some important differences between the two systems at the query executor level (in addition to the obvious differences at the storage layer level). Using the column-store, we then tease apart these differences, demonstrating the impact on performance of a variety of column-oriented query execution techniques, including vectorized query processing, compression, and a new join algorithm we introduce in this paper. We conclude that while it is not impossible for a row-store to achieve some of the performance advantages of a column-store, changes must be made to both the storage layer and the query executor to fully obtain the benefits of a column-oriented approach.},
  booktitle = {Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data},
  pages     = {967–980},
  numpages  = {14},
  keywords  = {tuple reconstruction, tuple materialization, invisible join, compression, column-store, column-oriented dbms, c-store},
  location  = {Vancouver, Canada},
  series    = {SIGMOD '08}
}

@article{kronrod1969optimal,
  author  = {Kronrod, M. A.},
  title   = {Optimal Ordering Algorithm without Operational Field},
  journal = {Soviet Mathematics Doklady},
  volume  = {10},
  pages   = {744--748},
  year    = {1969}
}

@article{10.1145/42392.42403,
  author     = {Huang, Bing-Chao and Langston, Michael A.},
  title      = {Practical in-place merging},
  year       = {1988},
  issue_date = {March 1988},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {31},
  number     = {3},
  issn       = {0001-0782},
  url        = {https://doi.org/10.1145/42392.42403},
  doi        = {10.1145/42392.42403},
  abstract   = {We present a novel, yet straightforward linear-time algorithm for merging two sorted lists in a fixed amount of additional space. Constant of proportionality estimates and empirical testing reveal that this procedure is reasonably competitive with merge routines free to squander unbounded additional memory, making it particularly attractive whenever space is a critical resource.},
  journal    = {Commun. ACM},
  month      = mar,
  pages      = {348–352},
  numpages   = {5}
}